{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import json\n",
    "# !pip install wordcloud\n",
    "from wordcloud import WordCloud\n",
    "import pickle\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install google-play-scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trashcare = pd.read_csv('/content/drive/MyDrive/KULIAH/Semester5/Pemrograman sistem Cerdas/Prak_AdiSucipto/Sentimen Analisis/trashcare.csv') #variable data berisikan data\n",
    "trashcare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trashcare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trashcare.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trashcare = trashcare.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trashcare.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trashcare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trashcare.to_csv('/content/drive/MyDrive/KULIAH/Semester5/Pemrograman sistem Cerdas/Prak_AdiSucipto/Sentimen Analisis/trashcare.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trashcare = pd.read_csv('/content/drive/MyDrive/KULIAH/Semester5/Pemrograman sistem Cerdas/Prak_AdiSucipto/Sentimen Analisis/trashcare.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trashcare.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trashcare[\"score\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = trashcare[\"content\"].tolist()\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = trashcare[\"score\"]\n",
    "y = to_categorical(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emoji(review):\n",
    "    # Smile -- :), : ), :-), (:, ( :, (-:, :') , :O\n",
    "    review = re.sub(r'(:\\s?\\)|:-\\)|\\(\\s?:|\\(-:|:\\'\\)|:O)', ' positiveemoji ', review)\n",
    "    # Laugh -- :D, : D, :-D, xD, x-D, XD, X-D\n",
    "    review = re.sub(r'(:\\s?D|:-D|x-?D|X-?D)', ' positiveemoji ', review)\n",
    "    # Love -- <3, :*\n",
    "    review = re.sub(r'(<3|:\\*)', ' positiveemoji ', review)\n",
    "    # Wink -- ;-), ;), ;-D, ;D, (;,  (-; , @-)\n",
    "    review = re.sub(r'(;-?\\)|;-?D|\\(-?;|@-\\))', ' positiveemoji ', review)\n",
    "    # Sad -- :-(, : (, :(, ):, )-:, :-/ , :-|\n",
    "    review = re.sub(r'(:\\s?\\(|:-\\(|\\)\\s?:|\\)-:|:-/|:-\\|)', ' negetiveemoji ', review)\n",
    "    # Cry -- :,(, :'(, :\"(\n",
    "    review = re.sub(r'(:,\\(|:\\'\\(|:\"\\()', ' negetiveemoji ', review)\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def process_review(review):\n",
    "    review = review.lower()                                             # Huruf kecil string\n",
    "    review = re.sub(r\"\\d+\", \" \", str(review))                           # Menghapus semua digit\n",
    "    review = re.sub('&quot;',\" \", review)                               # Hapus (&quot;)\n",
    "    review = emoji(review)                                              # Menggantikan Emoji\n",
    "    review = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", str(review))                   # Menghapus semua karakter tunggal\n",
    "    for word in review.split():\n",
    "        if word.lower() in contractions:\n",
    "            review = review.replace(word, contractions[word.lower()])   # Menggantikan kontraksi\n",
    "    review = re.sub(r'(.)\\1+', r'\\1\\1', review)                         # Ubah lebih dari 2 pengulangan huruf menjadi 2 huruf\n",
    "    review = re.sub(r\"\\s+\", \" \", str(review))                           # Replaces double spaces with single space\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trashcare.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer()\n",
    "token.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocal = len(token.index_word)+1\n",
    "vocal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case Folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trashcare = trashcare.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trashcare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(trashcare)):\n",
    "    if type(trashcare[\"content\"][i]) != str:\n",
    "        print(str(i), \"Bukan string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case Folding\n",
    "\n",
    "def clean_content(content):\n",
    "    import string, re\n",
    "\n",
    "    content = content.lower() # menjadikan lowercase\n",
    "    content = re.sub(\"[^a-z]\", \" \", content) # hapus semua karakter kecuali a-z\n",
    "    content = re.sub(\"\\t\", \" \", content) # mengganti tab dengan spasi\n",
    "    content = re.sub(\"\\n\", \" \", content) # mengganti new line dengan spasi\n",
    "    content = re.sub(\"\\s+\", \" \", content) # mengganti spasi > 1 dengan 1 spasi\n",
    "    content = content.strip() # menghapus spasi di awal dan akhir\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trashcare[\"content_clean\"] = trashcare[\"content\"].apply(clean_content)\n",
    "trashcare.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sastrawi\n",
    "pip install Sastrawi\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "factory = StopWordRemoverFactory()\n",
    "stopword_sastrawi = factory.get_stop_words()\n",
    "len(stopword_sastrawi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_nltk = set(stopwords.words(\"indonesian\"))\n",
    "len(stopword_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(stopword_nltk)\n",
    "df2 = pd.DataFrame(stopword_sastrawi)\n",
    "\n",
    "common = df1.merge(df2, on = [0], how = \"left\")\n",
    "print(common)\n",
    "\n",
    "ga_ada = df2[(~df2[0].isin(common[0]))] # ~ -> negasi (True jadi False)\n",
    "ga_ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_stopword(content):\n",
    "    # Stopword Sastrawi\n",
    "    from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "\n",
    "    factory = StopWordRemoverFactory()\n",
    "    stopword_sastrawi = factory.get_stop_words()\n",
    "\n",
    "    content = content.split() # split jadi kata per kata\n",
    "    content = [w for w in content if w not in stopword_sastrawi] # hapus stopwords\n",
    "    content = \" \".join(w for w in content) # join semua kata yang bukan stopwords\n",
    "\n",
    "    # Stopword NLTK\n",
    "    import nltk\n",
    "    #nltk.download()\n",
    "    from nltk.corpus import stopwords\n",
    "\n",
    "    stopword_nltk = set(stopwords.words(\"indonesian\"))\n",
    "    stopword_nltk = stopword_nltk\n",
    "\n",
    "    content = content.split() # split jadi kata per kata\n",
    "    content = [w for w in content if w not in stopword_nltk] # hapus stopwords\n",
    "    content = \" \".join(w for w in content) # join semua kata yang bukan stopwords\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trashcare[\"content_clean\"] = trashcare[\"content_clean\"].apply(clean_stopword)\n",
    "trashcare.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
